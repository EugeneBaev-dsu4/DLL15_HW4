{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef003194",
   "metadata": {},
   "source": [
    "### Домашняя работа 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507c59fe",
   "metadata": {},
   "source": [
    "### Основное задание\n",
    "\n",
    "Возьмите датасет https://www.kaggle.com/ajayrana/hymenoptera-data/kernels\n",
    " 1. Обучите на нем модели ResNet 18 и VGG 16 с нуля (5-10 эпох)\n",
    " 2. Обучите на нем модели ResNet 18 и VGG 16 с использованием FineTuning (5-10 эпох)\n",
    " 3. Добавьте аугментацию данных к пункту 2\n",
    "\n",
    "Сравните качество всех 3 полученных подходов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96680262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "\n",
    "import torchvision as tv\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395c6522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d79843ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../dll/hymenoptera_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32815913",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c596747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': tv.transforms.Compose([\n",
    "#         tv.transforms.RandomResizedCrop(224),\n",
    "#         tv.transforms.RandomHorizontalFlip(),\n",
    "#         tv.transforms.RandomVerticalFlip(),\n",
    "        tv.transforms.CenterCrop(224),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': tv.transforms.Compose([\n",
    "        tv.transforms.Resize(256),\n",
    "        tv.transforms.CenterCrop(224),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: tv.datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5eb0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18()\n",
    "vgg16 = models.vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "503a8b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\BEU_RU1/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50b0e0b75694f2196c57847751b116c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\BEU_RU1/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4783655662784e3da858149043fe84f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d69cb",
   "metadata": {},
   "source": [
    "#### 1.Обучите на нем модели ResNet 18 и VGG 16 с нуля (5-10 эпох)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60000b3e",
   "metadata": {},
   "source": [
    "### ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a79a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d974ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d67ba636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee121673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1b513d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 17.554. Train acc: 0.000. Train Loss: 229.013\n",
      "Step. time since epoch: 25.908. Train acc: 0.531. Train Loss: 181.447\n",
      "Step. time since epoch: 34.352. Train acc: 0.469. Train Loss: 168.221\n",
      "Step. time since epoch: 41.885. Train acc: 0.375. Train Loss: 171.311\n",
      "Step. time since epoch: 49.844. Train acc: 0.500. Train Loss: 115.404\n",
      "Step. time since epoch: 58.297. Train acc: 0.406. Train Loss: 95.773\n",
      "Step. time since epoch: 65.791. Train acc: 0.656. Train Loss: 53.171\n",
      "Step. time since epoch: 71.158. Train acc: 0.400. Train Loss: 27.094\n",
      "epoch 1, loss 4.2682, train acc 0.418, test acc 0.072, time 92.4 sec\n",
      "Step. time since epoch: 28.371. Train acc: 0.031. Train Loss: 1209.573\n",
      "Step. time since epoch: 36.451. Train acc: 0.469. Train Loss: 101.193\n",
      "Step. time since epoch: 46.102. Train acc: 0.562. Train Loss: 74.255\n",
      "Step. time since epoch: 54.066. Train acc: 0.438. Train Loss: 36.677\n",
      "Step. time since epoch: 62.473. Train acc: 0.625. Train Loss: 31.955\n",
      "Step. time since epoch: 70.094. Train acc: 0.531. Train Loss: 28.473\n",
      "Step. time since epoch: 78.642. Train acc: 0.469. Train Loss: 59.520\n",
      "Step. time since epoch: 83.542. Train acc: 0.500. Train Loss: 16.311\n",
      "epoch 2, loss 6.3851, train acc 0.451, test acc 0.542, time 104.4 sec\n",
      "Step. time since epoch: 14.661. Train acc: 0.406. Train Loss: 57.499\n",
      "Step. time since epoch: 23.067. Train acc: 0.406. Train Loss: 22.418\n",
      "Step. time since epoch: 30.214. Train acc: 0.469. Train Loss: 24.973\n",
      "Step. time since epoch: 36.918. Train acc: 0.500. Train Loss: 24.034\n",
      "Step. time since epoch: 42.445. Train acc: 0.562. Train Loss: 21.765\n",
      "Step. time since epoch: 48.338. Train acc: 0.594. Train Loss: 22.087\n",
      "Step. time since epoch: 54.828. Train acc: 0.344. Train Loss: 25.602\n",
      "Step. time since epoch: 58.555. Train acc: 0.550. Train Loss: 13.850\n",
      "epoch 3, loss 0.8698, train acc 0.475, test acc 0.536, time 74.4 sec\n",
      "Step. time since epoch: 11.302. Train acc: 0.562. Train Loss: 22.181\n",
      "Step. time since epoch: 17.533. Train acc: 0.562. Train Loss: 22.140\n",
      "Step. time since epoch: 24.089. Train acc: 0.594. Train Loss: 21.756\n",
      "Step. time since epoch: 30.568. Train acc: 0.312. Train Loss: 24.941\n",
      "Step. time since epoch: 36.666. Train acc: 0.500. Train Loss: 22.380\n",
      "Step. time since epoch: 43.239. Train acc: 0.688. Train Loss: 21.749\n",
      "Step. time since epoch: 49.519. Train acc: 0.406. Train Loss: 22.537\n",
      "Step. time since epoch: 53.165. Train acc: 0.550. Train Loss: 13.723\n",
      "epoch 4, loss 0.7025, train acc 0.520, test acc 0.451, time 68.7 sec\n",
      "Step. time since epoch: 12.439. Train acc: 0.531. Train Loss: 21.418\n",
      "Step. time since epoch: 19.835. Train acc: 0.594. Train Loss: 21.658\n",
      "Step. time since epoch: 26.993. Train acc: 0.500. Train Loss: 22.629\n",
      "Step. time since epoch: 32.290. Train acc: 0.469. Train Loss: 22.777\n",
      "Step. time since epoch: 39.227. Train acc: 0.438. Train Loss: 23.097\n",
      "Step. time since epoch: 45.771. Train acc: 0.344. Train Loss: 23.751\n",
      "Step. time since epoch: 53.411. Train acc: 0.438. Train Loss: 22.771\n",
      "Step. time since epoch: 57.919. Train acc: 0.550. Train Loss: 13.215\n",
      "epoch 5, loss 0.7021, train acc 0.480, test acc 0.418, time 71.2 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bed5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release CUDA\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc18e5",
   "metadata": {},
   "source": [
    "#### VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d58fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b459479",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68bf94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c3c9108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc7f03c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 68.127. Train acc: 0.000. Train Loss: 221.306\n",
      "Step. time since epoch: 149.176. Train acc: 0.500. Train Loss: 1075.133\n",
      "Step. time since epoch: 197.773. Train acc: 0.500. Train Loss: 108.346\n",
      "Step. time since epoch: 283.396. Train acc: 0.531. Train Loss: 897.750\n",
      "Step. time since epoch: 331.016. Train acc: 0.312. Train Loss: 188.278\n",
      "Step. time since epoch: 381.541. Train acc: 0.656. Train Loss: 197.094\n",
      "Step. time since epoch: 429.614. Train acc: 0.406. Train Loss: 187.530\n",
      "Step. time since epoch: 457.164. Train acc: 0.500. Train Loss: 78.040\n",
      "epoch 1, loss 12.1044, train acc 0.422, test acc 0.542, time 542.4 sec\n",
      "Step. time since epoch: 53.242. Train acc: 0.562. Train Loss: 98.553\n",
      "Step. time since epoch: 115.043. Train acc: 0.531. Train Loss: 30.052\n",
      "Step. time since epoch: 161.898. Train acc: 0.562. Train Loss: 34.733\n",
      "Step. time since epoch: 199.241. Train acc: 0.438. Train Loss: 54.199\n",
      "Step. time since epoch: 236.036. Train acc: 0.594. Train Loss: 35.792\n",
      "Step. time since epoch: 272.547. Train acc: 0.531. Train Loss: 33.971\n",
      "Step. time since epoch: 308.905. Train acc: 0.594. Train Loss: 24.869\n",
      "Step. time since epoch: 332.371. Train acc: 0.350. Train Loss: 16.487\n",
      "epoch 2, loss 1.3470, train acc 0.529, test acc 0.542, time 392.9 sec\n",
      "Step. time since epoch: 48.210. Train acc: 0.438. Train Loss: 22.951\n",
      "Step. time since epoch: 90.224. Train acc: 0.625. Train Loss: 21.480\n",
      "Step. time since epoch: 128.351. Train acc: 0.531. Train Loss: 26.494\n",
      "Step. time since epoch: 168.048. Train acc: 0.375. Train Loss: 32.123\n",
      "Step. time since epoch: 205.212. Train acc: 0.469. Train Loss: 24.516\n",
      "Step. time since epoch: 242.901. Train acc: 0.594. Train Loss: 22.152\n",
      "Step. time since epoch: 282.308. Train acc: 0.500. Train Loss: 24.134\n",
      "Step. time since epoch: 306.805. Train acc: 0.300. Train Loss: 20.674\n",
      "epoch 3, loss 0.7972, train acc 0.488, test acc 0.458, time 370.2 sec\n",
      "Step. time since epoch: 44.562. Train acc: 0.625. Train Loss: 21.875\n",
      "Step. time since epoch: 108.445. Train acc: 0.625. Train Loss: 21.398\n",
      "Step. time since epoch: 179.319. Train acc: 0.500. Train Loss: 23.362\n",
      "Step. time since epoch: 230.947. Train acc: 0.562. Train Loss: 21.934\n",
      "Step. time since epoch: 275.770. Train acc: 0.219. Train Loss: 22.501\n",
      "Step. time since epoch: 313.418. Train acc: 0.625. Train Loss: 21.303\n",
      "Step. time since epoch: 349.836. Train acc: 0.406. Train Loss: 25.937\n",
      "Step. time since epoch: 375.949. Train acc: 0.450. Train Loss: 16.103\n",
      "epoch 4, loss 0.7148, train acc 0.504, test acc 0.542, time 434.2 sec\n",
      "Step. time since epoch: 44.326. Train acc: 0.562. Train Loss: 23.013\n",
      "Step. time since epoch: 86.916. Train acc: 0.469. Train Loss: 24.940\n",
      "Step. time since epoch: 126.951. Train acc: 0.469. Train Loss: 24.320\n",
      "Step. time since epoch: 169.691. Train acc: 0.625. Train Loss: 21.714\n",
      "Step. time since epoch: 207.623. Train acc: 0.500. Train Loss: 22.929\n",
      "Step. time since epoch: 244.361. Train acc: 0.469. Train Loss: 22.729\n",
      "Step. time since epoch: 281.754. Train acc: 0.438. Train Loss: 22.404\n",
      "Step. time since epoch: 306.276. Train acc: 0.600. Train Loss: 13.674\n",
      "epoch 5, loss 0.7202, train acc 0.512, test acc 0.458, time 366.7 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627637e8",
   "metadata": {},
   "source": [
    "### 2.Обучите на нем модели ResNet 18 и VGG 16 с использованием FineTuning (5-10 эпох)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cb189f",
   "metadata": {},
   "source": [
    "#### ResNet 18 pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c061a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7704ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a11c2518",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Убираем требование градиента:\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3fba12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd1c9532",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(in_features=512, out_features=2).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dec60e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31c89009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78e451f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "850cd5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 6.007. Train acc: 0.562. Train Loss: 22.929\n",
      "Step. time since epoch: 8.148. Train acc: 0.594. Train Loss: 21.164\n",
      "Step. time since epoch: 10.181. Train acc: 0.562. Train Loss: 19.349\n",
      "Step. time since epoch: 12.168. Train acc: 0.562. Train Loss: 22.915\n",
      "Step. time since epoch: 15.136. Train acc: 0.594. Train Loss: 20.688\n",
      "Step. time since epoch: 18.230. Train acc: 0.812. Train Loss: 15.045\n",
      "Step. time since epoch: 20.349. Train acc: 0.750. Train Loss: 18.141\n",
      "Step. time since epoch: 21.725. Train acc: 0.850. Train Loss: 9.606\n",
      "epoch 1, loss 0.6141, train acc 0.652, test acc 0.667, time 35.6 sec\n",
      "Step. time since epoch: 6.489. Train acc: 0.688. Train Loss: 14.403\n",
      "Step. time since epoch: 8.442. Train acc: 0.688. Train Loss: 16.306\n",
      "Step. time since epoch: 10.576. Train acc: 0.688. Train Loss: 18.153\n",
      "Step. time since epoch: 12.558. Train acc: 0.750. Train Loss: 16.469\n",
      "Step. time since epoch: 14.478. Train acc: 0.969. Train Loss: 10.029\n",
      "Step. time since epoch: 16.344. Train acc: 0.844. Train Loss: 12.947\n",
      "Step. time since epoch: 18.292. Train acc: 0.906. Train Loss: 11.513\n",
      "Step. time since epoch: 19.455. Train acc: 0.850. Train Loss: 7.565\n",
      "epoch 2, loss 0.4401, train acc 0.795, test acc 0.908, time 33.3 sec\n",
      "Step. time since epoch: 5.537. Train acc: 0.781. Train Loss: 13.193\n",
      "Step. time since epoch: 7.344. Train acc: 0.938. Train Loss: 9.582\n",
      "Step. time since epoch: 9.509. Train acc: 0.844. Train Loss: 10.725\n",
      "Step. time since epoch: 11.355. Train acc: 0.875. Train Loss: 9.433\n",
      "Step. time since epoch: 13.251. Train acc: 0.844. Train Loss: 11.418\n",
      "Step. time since epoch: 15.186. Train acc: 0.906. Train Loss: 11.694\n",
      "Step. time since epoch: 17.102. Train acc: 0.906. Train Loss: 7.836\n",
      "Step. time since epoch: 18.299. Train acc: 0.850. Train Loss: 7.675\n",
      "epoch 3, loss 0.3343, train acc 0.869, test acc 0.941, time 32.1 sec\n",
      "Step. time since epoch: 5.580. Train acc: 0.906. Train Loss: 8.922\n",
      "Step. time since epoch: 7.413. Train acc: 0.938. Train Loss: 6.990\n",
      "Step. time since epoch: 9.508. Train acc: 0.938. Train Loss: 7.958\n",
      "Step. time since epoch: 11.375. Train acc: 0.969. Train Loss: 7.105\n",
      "Step. time since epoch: 13.150. Train acc: 0.844. Train Loss: 10.640\n",
      "Step. time since epoch: 15.088. Train acc: 0.969. Train Loss: 6.940\n",
      "Step. time since epoch: 17.136. Train acc: 0.938. Train Loss: 6.807\n",
      "Step. time since epoch: 18.281. Train acc: 0.950. Train Loss: 5.008\n",
      "epoch 4, loss 0.2474, train acc 0.930, test acc 0.922, time 32.1 sec\n",
      "Step. time since epoch: 5.622. Train acc: 0.938. Train Loss: 7.956\n",
      "Step. time since epoch: 7.421. Train acc: 0.938. Train Loss: 6.366\n",
      "Step. time since epoch: 9.873. Train acc: 1.000. Train Loss: 5.331\n",
      "Step. time since epoch: 11.779. Train acc: 0.938. Train Loss: 7.239\n",
      "Step. time since epoch: 13.616. Train acc: 0.969. Train Loss: 6.126\n",
      "Step. time since epoch: 15.530. Train acc: 0.969. Train Loss: 5.152\n",
      "Step. time since epoch: 17.521. Train acc: 0.969. Train Loss: 6.257\n",
      "Step. time since epoch: 20.339. Train acc: 0.950. Train Loss: 4.646\n",
      "epoch 5, loss 0.2011, train acc 0.959, test acc 0.967, time 40.2 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdcfef4",
   "metadata": {},
   "source": [
    "#### VGG 16 pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34192eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82bcd02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a26f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Убираем требование градиента:\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eccc21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74c85f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=2).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76eba5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5c9eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01da675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bd0cf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 18.334. Train acc: 0.656. Train Loss: 23.186\n",
      "Step. time since epoch: 31.569. Train acc: 0.781. Train Loss: 16.392\n",
      "Step. time since epoch: 46.943. Train acc: 0.844. Train Loss: 13.506\n",
      "Step. time since epoch: 60.508. Train acc: 0.875. Train Loss: 11.982\n",
      "Step. time since epoch: 72.866. Train acc: 0.938. Train Loss: 7.274\n",
      "Step. time since epoch: 85.267. Train acc: 0.906. Train Loss: 7.994\n",
      "Step. time since epoch: 98.255. Train acc: 0.875. Train Loss: 9.825\n",
      "Step. time since epoch: 105.977. Train acc: 1.000. Train Loss: 1.656\n",
      "epoch 1, loss 0.3763, train acc 0.852, test acc 0.954, time 174.7 sec\n",
      "Step. time since epoch: 15.217. Train acc: 1.000. Train Loss: 1.261\n",
      "Step. time since epoch: 26.462. Train acc: 0.969. Train Loss: 2.318\n",
      "Step. time since epoch: 37.865. Train acc: 0.875. Train Loss: 5.811\n",
      "Step. time since epoch: 50.055. Train acc: 0.969. Train Loss: 3.183\n",
      "Step. time since epoch: 62.608. Train acc: 1.000. Train Loss: 1.976\n",
      "Step. time since epoch: 74.993. Train acc: 0.938. Train Loss: 5.966\n",
      "Step. time since epoch: 86.358. Train acc: 0.969. Train Loss: 2.383\n",
      "Step. time since epoch: 93.443. Train acc: 1.000. Train Loss: 1.459\n",
      "epoch 2, loss 0.0998, train acc 0.963, test acc 0.954, time 153.9 sec\n",
      "Step. time since epoch: 17.126. Train acc: 1.000. Train Loss: 1.234\n",
      "Step. time since epoch: 28.547. Train acc: 1.000. Train Loss: 0.835\n",
      "Step. time since epoch: 40.002. Train acc: 0.969. Train Loss: 3.408\n",
      "Step. time since epoch: 51.126. Train acc: 0.938. Train Loss: 5.443\n",
      "Step. time since epoch: 62.407. Train acc: 0.969. Train Loss: 1.706\n",
      "Step. time since epoch: 73.798. Train acc: 1.000. Train Loss: 2.358\n",
      "Step. time since epoch: 84.578. Train acc: 1.000. Train Loss: 0.645\n",
      "Step. time since epoch: 91.504. Train acc: 1.000. Train Loss: 0.645\n",
      "epoch 3, loss 0.0667, train acc 0.984, test acc 0.961, time 148.1 sec\n",
      "Step. time since epoch: 15.290. Train acc: 1.000. Train Loss: 0.800\n",
      "Step. time since epoch: 27.104. Train acc: 0.969. Train Loss: 1.757\n",
      "Step. time since epoch: 38.291. Train acc: 0.969. Train Loss: 1.560\n",
      "Step. time since epoch: 49.980. Train acc: 1.000. Train Loss: 1.201\n",
      "Step. time since epoch: 60.618. Train acc: 1.000. Train Loss: 1.273\n",
      "Step. time since epoch: 71.712. Train acc: 1.000. Train Loss: 0.992\n",
      "Step. time since epoch: 83.010. Train acc: 0.969. Train Loss: 2.281\n",
      "Step. time since epoch: 89.967. Train acc: 1.000. Train Loss: 0.864\n",
      "epoch 4, loss 0.0440, train acc 0.988, test acc 0.967, time 146.7 sec\n",
      "Step. time since epoch: 14.885. Train acc: 1.000. Train Loss: 1.589\n",
      "Step. time since epoch: 25.664. Train acc: 1.000. Train Loss: 1.215\n",
      "Step. time since epoch: 36.539. Train acc: 1.000. Train Loss: 0.797\n",
      "Step. time since epoch: 47.569. Train acc: 1.000. Train Loss: 0.569\n",
      "Step. time since epoch: 58.019. Train acc: 1.000. Train Loss: 1.379\n",
      "Step. time since epoch: 69.739. Train acc: 1.000. Train Loss: 0.824\n",
      "Step. time since epoch: 81.318. Train acc: 1.000. Train Loss: 0.452\n",
      "Step. time since epoch: 88.275. Train acc: 1.000. Train Loss: 0.938\n",
      "epoch 5, loss 0.0318, train acc 1.000, test acc 0.974, time 147.7 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13f2ac",
   "metadata": {},
   "source": [
    "### 3.Добавьте аугментацию данных к пункту 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8bbbc4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': tv.transforms.Compose([\n",
    "        tv.transforms.RandomResizedCrop(224),\n",
    "        tv.transforms.RandomHorizontalFlip(),\n",
    "        tv.transforms.RandomVerticalFlip(),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': tv.transforms.Compose([\n",
    "        tv.transforms.Resize(256),\n",
    "        tv.transforms.CenterCrop(224),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: tv.datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e0fbcc",
   "metadata": {},
   "source": [
    "#### ResNet 18 pretrained + aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8aec31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce86a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c00d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Убираем требование градиента:\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa2ecef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9445ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(in_features=512, out_features=2).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22a41c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "baad77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4a1fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8099b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 6.277. Train acc: 0.500. Train Loss: 30.117\n",
      "Step. time since epoch: 8.236. Train acc: 0.469. Train Loss: 25.838\n",
      "Step. time since epoch: 10.655. Train acc: 0.406. Train Loss: 25.473\n",
      "Step. time since epoch: 13.001. Train acc: 0.500. Train Loss: 23.070\n",
      "Step. time since epoch: 15.636. Train acc: 0.562. Train Loss: 24.052\n",
      "Step. time since epoch: 17.982. Train acc: 0.562. Train Loss: 22.119\n",
      "Step. time since epoch: 20.520. Train acc: 0.750. Train Loss: 20.064\n",
      "Step. time since epoch: 21.774. Train acc: 0.450. Train Loss: 14.308\n",
      "epoch 1, loss 0.7584, train acc 0.529, test acc 0.791, time 35.1 sec\n",
      "Step. time since epoch: 5.560. Train acc: 0.656. Train Loss: 19.217\n",
      "Step. time since epoch: 7.659. Train acc: 0.781. Train Loss: 16.738\n",
      "Step. time since epoch: 9.612. Train acc: 0.719. Train Loss: 16.960\n",
      "Step. time since epoch: 11.500. Train acc: 0.656. Train Loss: 18.656\n",
      "Step. time since epoch: 13.347. Train acc: 0.719. Train Loss: 16.993\n",
      "Step. time since epoch: 15.040. Train acc: 0.844. Train Loss: 14.435\n",
      "Step. time since epoch: 16.874. Train acc: 0.875. Train Loss: 15.356\n",
      "Step. time since epoch: 18.018. Train acc: 0.850. Train Loss: 8.236\n",
      "epoch 2, loss 0.5188, train acc 0.758, test acc 0.922, time 31.5 sec\n",
      "Step. time since epoch: 5.452. Train acc: 0.844. Train Loss: 13.861\n",
      "Step. time since epoch: 7.442. Train acc: 0.875. Train Loss: 12.154\n",
      "Step. time since epoch: 9.338. Train acc: 0.812. Train Loss: 13.905\n",
      "Step. time since epoch: 11.140. Train acc: 0.969. Train Loss: 8.470\n",
      "Step. time since epoch: 13.083. Train acc: 0.969. Train Loss: 7.478\n",
      "Step. time since epoch: 14.995. Train acc: 0.906. Train Loss: 12.314\n",
      "Step. time since epoch: 16.984. Train acc: 0.875. Train Loss: 12.521\n",
      "Step. time since epoch: 18.316. Train acc: 0.800. Train Loss: 7.614\n",
      "epoch 3, loss 0.3620, train acc 0.885, test acc 0.948, time 31.7 sec\n",
      "Step. time since epoch: 5.797. Train acc: 0.938. Train Loss: 10.607\n",
      "Step. time since epoch: 7.943. Train acc: 0.969. Train Loss: 6.872\n",
      "Step. time since epoch: 10.091. Train acc: 0.781. Train Loss: 11.864\n",
      "Step. time since epoch: 12.315. Train acc: 0.906. Train Loss: 9.607\n",
      "Step. time since epoch: 14.650. Train acc: 0.844. Train Loss: 11.060\n",
      "Step. time since epoch: 16.955. Train acc: 1.000. Train Loss: 7.015\n",
      "Step. time since epoch: 19.336. Train acc: 0.906. Train Loss: 9.934\n",
      "Step. time since epoch: 20.926. Train acc: 0.950. Train Loss: 5.587\n",
      "epoch 4, loss 0.2973, train acc 0.910, test acc 0.948, time 35.5 sec\n",
      "Step. time since epoch: 6.119. Train acc: 0.750. Train Loss: 12.788\n",
      "Step. time since epoch: 7.935. Train acc: 0.906. Train Loss: 7.988\n",
      "Step. time since epoch: 9.831. Train acc: 0.906. Train Loss: 9.323\n",
      "Step. time since epoch: 11.649. Train acc: 0.906. Train Loss: 7.651\n",
      "Step. time since epoch: 13.521. Train acc: 0.875. Train Loss: 7.478\n",
      "Step. time since epoch: 15.299. Train acc: 0.938. Train Loss: 8.169\n",
      "Step. time since epoch: 17.197. Train acc: 0.969. Train Loss: 7.388\n",
      "Step. time since epoch: 18.354. Train acc: 0.850. Train Loss: 5.119\n",
      "epoch 5, loss 0.2701, train acc 0.889, test acc 0.954, time 31.6 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3eff22",
   "metadata": {},
   "source": [
    "### VGG 16 pretrained + aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd7bbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ec1449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b8d2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Убираем требование градиента:\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f61b90db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c49d4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=2).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "423d286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "150c85d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    net.eval()\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93ee5266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "537a0919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 16.622. Train acc: 0.594. Train Loss: 20.171\n",
      "Step. time since epoch: 27.230. Train acc: 0.688. Train Loss: 18.415\n",
      "Step. time since epoch: 38.401. Train acc: 0.875. Train Loss: 12.666\n",
      "Step. time since epoch: 48.837. Train acc: 0.969. Train Loss: 11.319\n",
      "Step. time since epoch: 61.952. Train acc: 0.906. Train Loss: 9.464\n",
      "Step. time since epoch: 74.581. Train acc: 0.875. Train Loss: 9.880\n",
      "Step. time since epoch: 88.087. Train acc: 0.906. Train Loss: 7.500\n",
      "Step. time since epoch: 95.043. Train acc: 0.950. Train Loss: 4.067\n",
      "epoch 1, loss 0.3831, train acc 0.840, test acc 0.961, time 157.1 sec\n",
      "Step. time since epoch: 16.435. Train acc: 0.906. Train Loss: 8.161\n",
      "Step. time since epoch: 27.498. Train acc: 0.906. Train Loss: 7.181\n",
      "Step. time since epoch: 38.357. Train acc: 0.906. Train Loss: 5.633\n",
      "Step. time since epoch: 48.807. Train acc: 1.000. Train Loss: 2.979\n",
      "Step. time since epoch: 59.759. Train acc: 1.000. Train Loss: 2.433\n",
      "Step. time since epoch: 70.791. Train acc: 0.938. Train Loss: 3.897\n",
      "Step. time since epoch: 81.130. Train acc: 0.906. Train Loss: 5.533\n",
      "Step. time since epoch: 88.040. Train acc: 0.950. Train Loss: 3.025\n",
      "epoch 2, loss 0.1592, train acc 0.939, test acc 0.954, time 142.9 sec\n",
      "Step. time since epoch: 15.558. Train acc: 0.906. Train Loss: 6.732\n",
      "Step. time since epoch: 26.635. Train acc: 1.000. Train Loss: 2.465\n",
      "Step. time since epoch: 37.290. Train acc: 1.000. Train Loss: 2.244\n",
      "Step. time since epoch: 48.399. Train acc: 1.000. Train Loss: 2.117\n",
      "Step. time since epoch: 60.225. Train acc: 0.906. Train Loss: 5.305\n",
      "Step. time since epoch: 71.275. Train acc: 0.844. Train Loss: 10.249\n",
      "Step. time since epoch: 82.368. Train acc: 0.938. Train Loss: 4.169\n",
      "Step. time since epoch: 89.576. Train acc: 0.950. Train Loss: 2.575\n",
      "epoch 3, loss 0.1469, train acc 0.943, test acc 0.961, time 147.0 sec\n",
      "Step. time since epoch: 14.916. Train acc: 0.938. Train Loss: 6.375\n",
      "Step. time since epoch: 26.385. Train acc: 0.969. Train Loss: 3.020\n",
      "Step. time since epoch: 37.071. Train acc: 0.906. Train Loss: 6.698\n",
      "Step. time since epoch: 47.429. Train acc: 0.969. Train Loss: 2.968\n",
      "Step. time since epoch: 58.161. Train acc: 0.938. Train Loss: 4.034\n",
      "Step. time since epoch: 69.051. Train acc: 1.000. Train Loss: 2.790\n",
      "Step. time since epoch: 80.034. Train acc: 0.969. Train Loss: 5.090\n",
      "Step. time since epoch: 86.943. Train acc: 1.000. Train Loss: 0.568\n",
      "epoch 4, loss 0.1293, train acc 0.959, test acc 0.961, time 141.2 sec\n",
      "Step. time since epoch: 14.884. Train acc: 0.938. Train Loss: 4.442\n",
      "Step. time since epoch: 25.850. Train acc: 0.875. Train Loss: 6.597\n",
      "Step. time since epoch: 36.348. Train acc: 0.969. Train Loss: 3.809\n",
      "Step. time since epoch: 47.018. Train acc: 0.906. Train Loss: 4.599\n",
      "Step. time since epoch: 58.441. Train acc: 0.969. Train Loss: 2.493\n",
      "Step. time since epoch: 69.064. Train acc: 0.938. Train Loss: 4.074\n",
      "Step. time since epoch: 79.857. Train acc: 0.969. Train Loss: 3.248\n",
      "Step. time since epoch: 86.581. Train acc: 1.000. Train Loss: 1.686\n",
      "epoch 5, loss 0.1268, train acc 0.943, test acc 0.967, time 141.9 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, dataloaders_dict['train'], dataloaders_dict['val'], trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15988152",
   "metadata": {},
   "source": [
    "#### Сравните качество всех 3 полученных подходов\n",
    "Качество обучения на тестовой и валидационной выборках в случае finetuning оказалось наилучшим. При этом предполагаем, что с учетом аугментации данных модель становится стабильнее."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa148f2",
   "metadata": {},
   "source": [
    "### 4. Примените FineTuning ResNet 18 к FashionMnist. Удалось ли увидеть резкое увеличение качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be50a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c9cd3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "transoforms = tv.transforms.Compose([\n",
    "    tv.transforms.Grayscale(3),\n",
    "    tv.transforms.Resize((224,224)),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "train_dataset = tv.datasets.MNIST('.', train=True, transform=transoforms, download=True)\n",
    "test_dataset = tv.datasets.MNIST('.', train=False, transform=transoforms, download=True)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a764736",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tv.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "59dd221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ab7d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Убираем требование градиента:\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c5f0bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d55d48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(in_features=512, out_features=10).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "779d4215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c5f5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, dev):\n",
    "    acc_sum, n = torch.Tensor([0]).to(dev), 0\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.to(dev), y.to(dev)\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum.item() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c01823ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, trainer, num_epochs, dev):\n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            print(\"Step. time since epoch: {:.3f}. Train acc: {:.3f}. Train Loss: {:.3f}\".format(time.time() -  start,\n",
    "                (y_hat.argmax(axis=1) == y).sum().item() / y.shape[0], l.item()))\n",
    "        test_acc = evaluate_accuracy(test_iter, net, dev)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "              'time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n",
    "                 time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1bdf2b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step. time since epoch: 15.101. Train acc: 0.129. Train Loss: 640.037\n",
      "Step. time since epoch: 31.788. Train acc: 0.102. Train Loss: 609.470\n",
      "Step. time since epoch: 47.723. Train acc: 0.141. Train Loss: 584.580\n",
      "Step. time since epoch: 63.548. Train acc: 0.199. Train Loss: 566.100\n",
      "Step. time since epoch: 78.856. Train acc: 0.160. Train Loss: 558.196\n",
      "Step. time since epoch: 94.336. Train acc: 0.250. Train Loss: 550.166\n",
      "Step. time since epoch: 110.334. Train acc: 0.266. Train Loss: 519.706\n",
      "Step. time since epoch: 125.844. Train acc: 0.293. Train Loss: 508.794\n",
      "Step. time since epoch: 141.184. Train acc: 0.441. Train Loss: 478.146\n",
      "Step. time since epoch: 156.429. Train acc: 0.410. Train Loss: 486.891\n",
      "Step. time since epoch: 172.772. Train acc: 0.512. Train Loss: 457.443\n",
      "Step. time since epoch: 188.440. Train acc: 0.516. Train Loss: 459.801\n",
      "Step. time since epoch: 203.810. Train acc: 0.598. Train Loss: 431.280\n",
      "Step. time since epoch: 219.836. Train acc: 0.637. Train Loss: 416.222\n",
      "Step. time since epoch: 235.693. Train acc: 0.633. Train Loss: 403.364\n",
      "Step. time since epoch: 251.890. Train acc: 0.609. Train Loss: 405.588\n",
      "Step. time since epoch: 267.926. Train acc: 0.648. Train Loss: 395.454\n",
      "Step. time since epoch: 283.871. Train acc: 0.684. Train Loss: 375.933\n",
      "Step. time since epoch: 299.326. Train acc: 0.734. Train Loss: 368.495\n",
      "Step. time since epoch: 314.696. Train acc: 0.746. Train Loss: 355.213\n",
      "Step. time since epoch: 330.693. Train acc: 0.746. Train Loss: 348.540\n",
      "Step. time since epoch: 346.750. Train acc: 0.777. Train Loss: 336.561\n",
      "Step. time since epoch: 362.598. Train acc: 0.730. Train Loss: 342.271\n",
      "Step. time since epoch: 378.098. Train acc: 0.758. Train Loss: 337.532\n",
      "Step. time since epoch: 393.749. Train acc: 0.773. Train Loss: 319.244\n",
      "Step. time since epoch: 409.965. Train acc: 0.820. Train Loss: 287.774\n",
      "Step. time since epoch: 425.681. Train acc: 0.789. Train Loss: 295.137\n",
      "Step. time since epoch: 441.314. Train acc: 0.801. Train Loss: 289.027\n",
      "Step. time since epoch: 456.596. Train acc: 0.793. Train Loss: 289.378\n",
      "Step. time since epoch: 472.428. Train acc: 0.840. Train Loss: 261.304\n",
      "Step. time since epoch: 488.172. Train acc: 0.832. Train Loss: 282.686\n",
      "Step. time since epoch: 504.184. Train acc: 0.809. Train Loss: 269.126\n",
      "Step. time since epoch: 519.668. Train acc: 0.840. Train Loss: 272.214\n",
      "Step. time since epoch: 535.287. Train acc: 0.758. Train Loss: 284.568\n",
      "Step. time since epoch: 550.650. Train acc: 0.820. Train Loss: 269.549\n",
      "Step. time since epoch: 565.900. Train acc: 0.902. Train Loss: 208.333\n",
      "Step. time since epoch: 581.876. Train acc: 0.828. Train Loss: 238.287\n",
      "Step. time since epoch: 597.576. Train acc: 0.879. Train Loss: 223.599\n",
      "Step. time since epoch: 613.326. Train acc: 0.906. Train Loss: 198.021\n",
      "Step. time since epoch: 629.133. Train acc: 0.844. Train Loss: 234.519\n",
      "Step. time since epoch: 645.493. Train acc: 0.836. Train Loss: 234.906\n",
      "Step. time since epoch: 661.262. Train acc: 0.895. Train Loss: 197.296\n",
      "Step. time since epoch: 676.488. Train acc: 0.891. Train Loss: 206.235\n",
      "Step. time since epoch: 692.195. Train acc: 0.859. Train Loss: 210.178\n",
      "Step. time since epoch: 708.457. Train acc: 0.848. Train Loss: 197.524\n",
      "Step. time since epoch: 723.913. Train acc: 0.891. Train Loss: 199.591\n",
      "Step. time since epoch: 741.098. Train acc: 0.859. Train Loss: 205.814\n",
      "Step. time since epoch: 758.499. Train acc: 0.883. Train Loss: 198.033\n",
      "Step. time since epoch: 775.988. Train acc: 0.867. Train Loss: 199.401\n",
      "Step. time since epoch: 792.758. Train acc: 0.871. Train Loss: 196.074\n",
      "Step. time since epoch: 809.033. Train acc: 0.832. Train Loss: 211.447\n",
      "Step. time since epoch: 825.258. Train acc: 0.848. Train Loss: 214.126\n",
      "Step. time since epoch: 841.830. Train acc: 0.902. Train Loss: 165.898\n",
      "Step. time since epoch: 858.078. Train acc: 0.898. Train Loss: 177.595\n",
      "Step. time since epoch: 874.288. Train acc: 0.863. Train Loss: 192.853\n",
      "Step. time since epoch: 891.632. Train acc: 0.879. Train Loss: 183.073\n",
      "Step. time since epoch: 908.933. Train acc: 0.848. Train Loss: 190.412\n",
      "Step. time since epoch: 927.673. Train acc: 0.879. Train Loss: 182.001\n",
      "Step. time since epoch: 944.397. Train acc: 0.906. Train Loss: 154.306\n",
      "Step. time since epoch: 960.396. Train acc: 0.926. Train Loss: 146.722\n",
      "Step. time since epoch: 976.175. Train acc: 0.891. Train Loss: 157.097\n",
      "Step. time since epoch: 991.990. Train acc: 0.824. Train Loss: 187.114\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7076/365911098.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7076/3189490305.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, train_iter, test_iter, trainer, num_epochs, dev)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    441\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 443\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 1\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train(model, train_iter, test_iter, trainer, num_epochs, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea01607",
   "metadata": {},
   "source": [
    "хорошо обучается и выходит за 90-92% на сравнительном быстром периоде обучения, чем обычная сетка, но в определенный момент начинает переобучаться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda4e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
